{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import re\n",
    "\n",
    "# Multiprocessing\n",
    "import multiprocess as mp\n",
    "import concurrent.futures\n",
    "import threading\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Country codes\n",
    "import pycountry\n",
    "\n",
    "# Rasters - pixel data\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "# Polygons - country outlines\n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "from scripts.countryoutlines import CountryOutlines  # custom class\n",
    "\n",
    "# Custom classes for Hansen et al., 2013\n",
    "from scripts.hansenhandler import HansenHandler, DataType\n",
    "from scripts.tile import Tile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get country ISO alpha 3 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO add extra countries\n",
    "countries = np.array([[country.alpha_3, country.name] for country in pycountry.countries])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate bounds for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries_run = countries[:20]  # Can debug on a subset\n",
    "\n",
    "try:\n",
    "    # Here's one I made earlier\n",
    "    df = pd.read_csv(\"interim/country_bounds.csv\", index_col=[0,1])\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Code to create country bounds\n",
    "\n",
    "    # Uses multiprocessing to speed up\n",
    "    nProcesses = 2 * mp.cpu_count()\n",
    "\n",
    "    with mp.get_context(\"spawn\").Pool(nProcesses) as pool:\n",
    "        # N.B. for countries spanning the date line,\n",
    "        # two sets of bounds are created, one each side\n",
    "        country_bounds = pool.starmap(CountryOutlines.get_bounds, countries)  \n",
    "\n",
    "    # Combine calculations from different processes\n",
    "    # TODO make index come out nicely\n",
    "    df = pd.concat(country_bounds).reset_index().drop(\"index\")\n",
    "    # Save\n",
    "    df.to_csv(\"interim/country_bounds.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create rectangle for calculations by tropics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cancer = 23.4372\n",
    "capricorn = -23.4394\n",
    "tropics = Polygon([(-180,cancer),(-180,capricorn),(180,capricorn),(180,cancer)])\n",
    "tropics = gpd.GeoDataFrame(geometry=[tropics])\n",
    "\n",
    "plot = False\n",
    "if plot:\n",
    "    ax = tropics.plot(facecolor=(1,1,1,0.4), edgecolor='white', linewidth=0.5)\n",
    "\n",
    "    with rasterio.open(\"raw/VCF5KYR_1982001_001_2018224204211.tif\") as f:\n",
    "        b1 = f.read(1)\n",
    "        b2 = f.read(2)\n",
    "        b3 = f.read(3)\n",
    "        bands = np.stack((b1,b2,b3),axis=0) / 100\n",
    "\n",
    "        show(bands, transform=f.transform, ax=ax)\n",
    "\n",
    "    del b1, b2, b3, bands, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start computing means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# hh = HansenHandler\n",
    "# This code could maybe go in hansenhandler?\n",
    "latlong = [(lat, long) for lat in range(-50,90,10) for long in range(-180,180,10)]\n",
    "\n",
    "# floor10 = lambda x: np.floor(x/10)*10\n",
    "# ceil10 = lambda x: np.ceil(x/10)*10\n",
    "# count_side = lambda start, end: (ceil10(end) - floor10(start)) / 10\n",
    "# count_tiles = lambda df: count_side(df.minx, df.maxx) * count_side(df.miny, df.maxy)\n",
    "\n",
    "# df = df.assign(nTiles = count_tiles)\n",
    "\n",
    "# df[\"nTiles\"] = df.groupby(\"country\")[\"nTiles\"].transform(\"sum\")\n",
    "\n",
    "\n",
    "latlong.index((10,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outlines as they are being used\n",
    "outlines = {country: None for country in df.country.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_band(raster, mask_band = None, window = None, return_affine=False):\n",
    "    if window:\n",
    "        band = raster.read(1, window=window)\n",
    "        affine = raster.window_transform(window)\n",
    "    else:\n",
    "        band = raster.read(1) #, window=win)\n",
    "        affine = raster.transform  # window_transform(win)\n",
    "\n",
    "    # if mask_band:\n",
    "    #     band[mask_band] = 255\n",
    "    if return_affine:\n",
    "        return (band, affine)\n",
    "    else:\n",
    "        return band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['minx', 'miny', 'maxx', 'maxy', 'country', 'nTiles', 'code', 'area',\n",
      "       'cover_2000', 'gain', 'loss1', 'loss2', 'loss3', 'loss4', 'loss5',\n",
      "       'loss6', 'loss7', 'loss8', 'loss9', 'loss10', 'loss11', 'loss12',\n",
      "       'loss13', 'loss14', 'loss15', 'loss16', 'loss17', 'loss18', 'loss19',\n",
      "       'loss20'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Things start to take a long time and use a lot of memory from here\n",
    "# so may move to Econ server\n",
    "\n",
    "# win = rasterio.windows.Window(20000,20000,20010,20010)\n",
    "win = None\n",
    "\n",
    "df[[\"code\",\"area\", \"cover_2000\", \"gain\", *(f\"loss{y}\" for y in range(1,21))]] = 0\n",
    "\n",
    "i = 0\n",
    "for coords in latlong:\n",
    "    tile = Tile(*coords)\n",
    "    # Subset countries whose bounds overlap\n",
    "    countries = df[tile.covers_country(df)]\n",
    "    \n",
    "    # Check if no countries overlap\n",
    "    if countries.empty:\n",
    "        continue\n",
    "\n",
    "    with tile.load_data(DataType.datamask) as mask_raster:\n",
    "        mask, mask_affine = read_band(mask_raster, window=win, return_affine=True)\n",
    "        \n",
    "        # Check if the tile has no data\n",
    "        # Might catch situations where country bounding box overlaps but country does not\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        area = np.random.random(mask.shape)\n",
    "        # TODO remove brackets\n",
    "        with (tile.load_data(DataType.treecover2000) as cover_raster,\n",
    "            tile.load_data(DataType.gain)            as gain_raster,\n",
    "            tile.load_data(DataType.lossyear)        as lossyear_raster):\n",
    "\n",
    "            cover = read_band(cover_raster, window=win)\n",
    "            # cover[cover <= 25] = 0\n",
    "            # gain = read_band(gain_raster, window=win)\n",
    "            # lossyear = read_band(lossyear_raster, window=win)\n",
    "            countries = countries.droplevel(\"group\")\n",
    "            \n",
    "            for c, row in countries.iterrows():\n",
    "                # Load and save border if not already loaded\n",
    "                country = row.country\n",
    "                outline_gdf = outlines[country]\n",
    "                if outline_gdf is None:\n",
    "                    outlines[country] = outline_gdf = CountryOutlines.load_country(c)\n",
    "                \n",
    "                geom = outline_gdf.geometry\n",
    "                \n",
    "                # Or start here\n",
    "                geom = rasterize(geom, out_shape=mask.shape, transform=mask_affine)\n",
    "                \n",
    "                # Check if geom is empty\n",
    "                if not np.any(geom):\n",
    "                    print(c, tile.lat, tile.long)\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                # Either start here\n",
    "                # c for country\n",
    "                mask_c      = mask * geom == 1\n",
    "                area_c      = area[mask_c]\n",
    "                cover_c     = cover[mask_c]\n",
    "                # lossyear_c  = lossyear[mask_c]\n",
    "                # gain_c      = gain[mask_c]\n",
    "\n",
    "                # _, n = np.unique(mask.flatten(), return_counts=True)\n",
    "                df.loc[c,\"area\"].values[0] += area_c.sum()\n",
    "\n",
    "                # Look into tensorflow one hot\n",
    "                df.loc[c,\"cover_2000\"].values[0] += (cover_c * area_c).sum()\n",
    "\n",
    "                # df.loc[c, \"gain\"] += (gain_c * area_c).sum()\n",
    "\n",
    "                # for year in range(1,20):\n",
    "                #     yearmask = lossyear_c == year\n",
    "                #     loss_cy = lossyear_c[yearmask]\n",
    "                #     cover_cy = cover_c[yearmask]\n",
    "                #     area_cy = area_c[yearmask]\n",
    "\n",
    "                #     df.loc[c, f\"loss_{year}\"] += (loss_cy * cover_cy * area_cy).sum()\n",
    "\n",
    "                i += 1\n",
    "                if i > 0:\n",
    "                    break\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "1    10.0\n",
       "Name: area, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"ATA\",\"area\"].values[0] += 2\n",
    "df.loc[\"ATA\",\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draft code for parallelisation\n",
    "\n",
    "# def main(infile, outfile, num_workers=4):\n",
    "#     \"\"\"Process infile block-by-block and write to a new file\n",
    "\n",
    "#     The output is the same as the input, but with band order\n",
    "#     reversed.\n",
    "#     \"\"\"\n",
    "\n",
    "#     with rasterio.open(infile) as src:\n",
    "\n",
    "#         # Create a destination dataset based on source params. The\n",
    "#         # destination will be tiled, and we'll process the tiles\n",
    "#         # concurrently.\n",
    "#         profile = src.profile\n",
    "#         profile.update(blockxsize=128, blockysize=128, tiled=True)\n",
    "\n",
    "#         with rasterio.open(outfile, \"w\", **src.profile) as dst:\n",
    "#             windows = [window for ij, window in dst.block_windows()]\n",
    "\n",
    "#             # We cannot write to the same file from multiple threads\n",
    "#             # without causing race conditions. To safely read/write\n",
    "#             # from multiple threads, we use a lock to protect the\n",
    "#             # DatasetReader/Writer\n",
    "#             read_lock = threading.Lock()\n",
    "#             write_lock = threading.Lock()\n",
    "\n",
    "#             def process(window):\n",
    "#                 with read_lock:\n",
    "#                     src_array = src.read(window=window)\n",
    "\n",
    "#                 # The computation can be performed concurrently\n",
    "#                 result = compute(src_array)\n",
    "\n",
    "#                 with write_lock:\n",
    "#                     dst.write(result, window=window)\n",
    "\n",
    "#             # We map the process() function over the list of\n",
    "#             # windows.\n",
    "#             with concurrent.futures.ThreadPoolExecutor(\n",
    "#                 max_workers=num_workers\n",
    "#             ) as executor:\n",
    "#                 executor.map(process, windows)\n",
    "#         # For each \n",
    "\n",
    "        \n",
    "#         #     cover, cover_affine = read_band(cover, mask)\n",
    "#         #     write_pixel_counts(countries, df, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_of_pixels(lat_start, lat_end, n_pixels):\n",
    "    \"\"\"Calculate m^2 area of an ndarray of wgs84 square pixels.\n",
    "\n",
    "    Adapted from: https://gis.stackexchange.com/a/127327/2397\n",
    "    \n",
    "    \"\"\"\n",
    "    a = 6378137  # meters\n",
    "    b = 6356752.3142  # meters\n",
    "    e = np.sqrt(1 - (b/a)**2)\n",
    "    lower = np.linspace(lat_start, lat_end, n_pixels, endpoint=False)\n",
    "    \n",
    "    higher = np.append(lower[1:], lat_end)\n",
    "    pixel_size = (lat_end - lat_start) / n_pixels\n",
    "    def subcalc(lats):\n",
    "        sin_lats = np.sin(np.radians(lats))\n",
    "        e_sin_lats = e*sin_lats\n",
    "        zm = 1 - e_sin_lats\n",
    "        zp = 1 + e_sin_lats\n",
    "        return np.pi * b**2 * (np.arctanh(e_sin_lats) / e + sin_lats / (zp*zm))\n",
    "\n",
    "    return pixel_size / 360. * (subcalc(higher) - subcalc(lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.92329103e+08, 1.92329103e+08, 1.92329103e+08, 1.92329103e+08],\n",
       "       [1.92328212e+08, 1.92328212e+08, 1.92328212e+08, 1.92328212e+08],\n",
       "       [1.92326430e+08, 1.92326430e+08, 1.92326430e+08, 1.92326430e+08],\n",
       "       [1.92323757e+08, 1.92323757e+08, 1.92323757e+08, 1.92323757e+08]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# area_of_pixels(0, )\n",
    "test = \"3077.2300079\"  # official number for pixel going 30' north of equator\n",
    "# TODO cite source\n",
    "\n",
    "test2 = area_of_pixels(0,0.5,4)\n",
    "\n",
    "np.tile(test2.reshape((-1,1)), (1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draft code to calculate extra countries\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# ['XSP: Spratly Islands_1', 'XCA: Caspian Sea_1', 'XKO: Kosovo_3', 'XPI: Paracel Islands_1', 'ZNC: Northern Cyprus_2', 'XAD: Not found', 'XCL: Not found']\n",
    "# \"\"\"\n",
    "\n",
    "# test2 = \n",
    "\n",
    "# test = test.splitlines()\n",
    "# test = [re.match(r'gadm40_(\\w+).gpkg', line).groups()[0] for line in test]\n",
    "# missing = set(test).difference(set([c.alpha_3 for c in pycountry.countries]))\n",
    "# names = {c.alpha_3: c.name for c in pycountry.countries}\n",
    "# missing\n",
    "\n",
    "# test2 = test2.splitlines()\n",
    "# test2 = [re.match(r'.*\"([A-Z]+)_(.+)\".*',line).groups() for line in test2]\n",
    "# test2 = {k: v for (k,v) in test2}\n",
    "# print([f\"{k}: {test2[k]}\" if k in test2 else f\"{k}: Not found\" for k in missing])\n",
    "# m = re.match(r'.*\"([A-Z]+)_([A-Za-z]+).*','<option value=\"VNM_Vietnam_4\">Vietnam</option>')\n",
    "# m.groups()\n",
    "# countries"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b750f273eab6bb805c9eba9b8f1c61f9aebec348bb54ede6125b0e9e60b3561"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
